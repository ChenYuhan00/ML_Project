{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:33:25.593592Z",
     "start_time": "2023-12-04T11:33:13.552066Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:33:25.656417Z",
     "start_time": "2023-12-04T11:33:25.574920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:33:25.819243Z",
     "start_time": "2023-12-04T11:33:25.620526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          image             label\n",
      "0  images/0.jpg  maclura_pomifera\n",
      "1  images/1.jpg  maclura_pomifera\n",
      "2  images/2.jpg  maclura_pomifera\n",
      "3  images/3.jpg  maclura_pomifera\n",
      "4  images/4.jpg  maclura_pomifera\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18353</td>\n",
       "      <td>18353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>18353</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>images/0.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image             label\n",
       "count          18353             18353\n",
       "unique         18353               176\n",
       "top     images/0.jpg  maclura_pomifera\n",
       "freq               1               353"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入并查看数据\n",
    "data_dir = '../dataset/'\n",
    "samples_dir = data_dir + 'train.csv'\n",
    "test_samples_dir = data_dir + 'test.csv'\n",
    "\n",
    "df = pd.read_csv(samples_dir)\n",
    "print(df.head())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:34:08.036667Z",
     "start_time": "2023-12-04T11:34:07.888375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image0 = plt.imread(os.path.join(data_dir, 'images/0.jpg'))\n",
    "image0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:34:09.285616Z",
     "start_time": "2023-12-04T11:34:09.016819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "['abies_concolor' 'abies_nordmanniana' 'acer_campestre' 'acer_ginnala'\n",
      " 'acer_griseum' 'acer_negundo' 'acer_palmatum' 'acer_pensylvanicum'\n",
      " 'acer_platanoides' 'acer_pseudoplatanus' 'acer_rubrum' 'acer_saccharinum'\n",
      " 'acer_saccharum' 'aesculus_flava' 'aesculus_glabra'\n",
      " 'aesculus_hippocastamon' 'aesculus_pavi' 'ailanthus_altissima'\n",
      " 'albizia_julibrissin' 'amelanchier_arborea' 'amelanchier_canadensis'\n",
      " 'amelanchier_laevis' 'asimina_triloba' 'betula_alleghaniensis'\n",
      " 'betula_jacqemontii' 'betula_lenta' 'betula_nigra' 'betula_populifolia'\n",
      " 'broussonettia_papyrifera' 'carpinus_betulus' 'carpinus_caroliniana'\n",
      " 'carya_cordiformis' 'carya_glabra' 'carya_ovata' 'carya_tomentosa'\n",
      " 'castanea_dentata' 'catalpa_bignonioides' 'catalpa_speciosa'\n",
      " 'cedrus_atlantica' 'cedrus_deodara' 'cedrus_libani' 'celtis_occidentalis'\n",
      " 'celtis_tenuifolia' 'cercidiphyllum_japonicum' 'cercis_canadensis'\n",
      " 'chamaecyparis_pisifera' 'chamaecyparis_thyoides' 'chionanthus_retusus'\n",
      " 'chionanthus_virginicus' 'cladrastis_lutea' 'cornus_florida'\n",
      " 'cornus_kousa' 'cornus_mas' 'crataegus_crus-galli' 'crataegus_laevigata'\n",
      " 'crataegus_phaenopyrum' 'crataegus_pruinosa' 'crataegus_viridis'\n",
      " 'cryptomeria_japonica' 'diospyros_virginiana' 'eucommia_ulmoides'\n",
      " 'evodia_daniellii' 'fagus_grandifolia' 'ficus_carica' 'fraxinus_nigra'\n",
      " 'fraxinus_pennsylvanica' 'ginkgo_biloba' 'gleditsia_triacanthos'\n",
      " 'gymnocladus_dioicus' 'halesia_tetraptera' 'ilex_opaca' 'juglans_cinerea'\n",
      " 'juglans_nigra' 'juniperus_virginiana' 'koelreuteria_paniculata'\n",
      " 'larix_decidua' 'liquidambar_styraciflua' 'liriodendron_tulipifera'\n",
      " 'maclura_pomifera' 'magnolia_acuminata' 'magnolia_denudata'\n",
      " 'magnolia_grandiflora' 'magnolia_macrophylla' 'magnolia_stellata'\n",
      " 'magnolia_tripetala' 'magnolia_virginiana' 'malus_baccata'\n",
      " 'malus_coronaria' 'malus_floribunda' 'malus_hupehensis' 'malus_pumila'\n",
      " 'metasequoia_glyptostroboides' 'morus_alba' 'morus_rubra'\n",
      " 'nyssa_sylvatica' 'ostrya_virginiana' 'oxydendrum_arboreum'\n",
      " 'paulownia_tomentosa' 'phellodendron_amurense' 'picea_abies'\n",
      " 'picea_orientalis' 'picea_pungens' 'pinus_bungeana' 'pinus_cembra'\n",
      " 'pinus_densiflora' 'pinus_echinata' 'pinus_flexilis' 'pinus_koraiensis'\n",
      " 'pinus_nigra' 'pinus_parviflora' 'pinus_peucea' 'pinus_pungens'\n",
      " 'pinus_resinosa' 'pinus_rigida' 'pinus_strobus' 'pinus_sylvestris'\n",
      " 'pinus_taeda' 'pinus_thunbergii' 'pinus_virginiana' 'pinus_wallichiana'\n",
      " 'platanus_acerifolia' 'platanus_occidentalis' 'populus_deltoides'\n",
      " 'populus_grandidentata' 'populus_tremuloides' 'prunus_pensylvanica'\n",
      " 'prunus_sargentii' 'prunus_serotina' 'prunus_serrulata'\n",
      " 'prunus_subhirtella' 'prunus_virginiana' 'prunus_yedoensis'\n",
      " 'pseudolarix_amabilis' 'ptelea_trifoliata' 'pyrus_calleryana'\n",
      " 'quercus_acutissima' 'quercus_alba' 'quercus_bicolor' 'quercus_cerris'\n",
      " 'quercus_coccinea' 'quercus_imbricaria' 'quercus_macrocarpa'\n",
      " 'quercus_marilandica' 'quercus_michauxii' 'quercus_montana'\n",
      " 'quercus_muehlenbergii' 'quercus_nigra' 'quercus_palustris'\n",
      " 'quercus_phellos' 'quercus_robur' 'quercus_shumardii' 'quercus_stellata'\n",
      " 'quercus_velutina' 'quercus_virginiana' 'robinia_pseudo-acacia'\n",
      " 'salix_babylonica' 'salix_caroliniana' 'salix_matsudana' 'salix_nigra'\n",
      " 'sassafras_albidum' 'staphylea_trifolia' 'stewartia_pseudocamellia'\n",
      " 'styrax_japonica' 'taxodium_distichum' 'tilia_americana' 'tilia_cordata'\n",
      " 'tilia_europaea' 'tilia_tomentosa' 'tsuga_canadensis' 'ulmus_americana'\n",
      " 'ulmus_glabra' 'ulmus_parvifolia' 'ulmus_procera' 'ulmus_pumila'\n",
      " 'ulmus_rubra' 'zelkova_serrata']\n",
      "{'abies_concolor': 0, 'abies_nordmanniana': 1, 'acer_campestre': 2, 'acer_ginnala': 3, 'acer_griseum': 4, 'acer_negundo': 5, 'acer_palmatum': 6, 'acer_pensylvanicum': 7, 'acer_platanoides': 8, 'acer_pseudoplatanus': 9, 'acer_rubrum': 10, 'acer_saccharinum': 11, 'acer_saccharum': 12, 'aesculus_flava': 13, 'aesculus_glabra': 14, 'aesculus_hippocastamon': 15, 'aesculus_pavi': 16, 'ailanthus_altissima': 17, 'albizia_julibrissin': 18, 'amelanchier_arborea': 19, 'amelanchier_canadensis': 20, 'amelanchier_laevis': 21, 'asimina_triloba': 22, 'betula_alleghaniensis': 23, 'betula_jacqemontii': 24, 'betula_lenta': 25, 'betula_nigra': 26, 'betula_populifolia': 27, 'broussonettia_papyrifera': 28, 'carpinus_betulus': 29, 'carpinus_caroliniana': 30, 'carya_cordiformis': 31, 'carya_glabra': 32, 'carya_ovata': 33, 'carya_tomentosa': 34, 'castanea_dentata': 35, 'catalpa_bignonioides': 36, 'catalpa_speciosa': 37, 'cedrus_atlantica': 38, 'cedrus_deodara': 39, 'cedrus_libani': 40, 'celtis_occidentalis': 41, 'celtis_tenuifolia': 42, 'cercidiphyllum_japonicum': 43, 'cercis_canadensis': 44, 'chamaecyparis_pisifera': 45, 'chamaecyparis_thyoides': 46, 'chionanthus_retusus': 47, 'chionanthus_virginicus': 48, 'cladrastis_lutea': 49, 'cornus_florida': 50, 'cornus_kousa': 51, 'cornus_mas': 52, 'crataegus_crus-galli': 53, 'crataegus_laevigata': 54, 'crataegus_phaenopyrum': 55, 'crataegus_pruinosa': 56, 'crataegus_viridis': 57, 'cryptomeria_japonica': 58, 'diospyros_virginiana': 59, 'eucommia_ulmoides': 60, 'evodia_daniellii': 61, 'fagus_grandifolia': 62, 'ficus_carica': 63, 'fraxinus_nigra': 64, 'fraxinus_pennsylvanica': 65, 'ginkgo_biloba': 66, 'gleditsia_triacanthos': 67, 'gymnocladus_dioicus': 68, 'halesia_tetraptera': 69, 'ilex_opaca': 70, 'juglans_cinerea': 71, 'juglans_nigra': 72, 'juniperus_virginiana': 73, 'koelreuteria_paniculata': 74, 'larix_decidua': 75, 'liquidambar_styraciflua': 76, 'liriodendron_tulipifera': 77, 'maclura_pomifera': 78, 'magnolia_acuminata': 79, 'magnolia_denudata': 80, 'magnolia_grandiflora': 81, 'magnolia_macrophylla': 82, 'magnolia_stellata': 83, 'magnolia_tripetala': 84, 'magnolia_virginiana': 85, 'malus_baccata': 86, 'malus_coronaria': 87, 'malus_floribunda': 88, 'malus_hupehensis': 89, 'malus_pumila': 90, 'metasequoia_glyptostroboides': 91, 'morus_alba': 92, 'morus_rubra': 93, 'nyssa_sylvatica': 94, 'ostrya_virginiana': 95, 'oxydendrum_arboreum': 96, 'paulownia_tomentosa': 97, 'phellodendron_amurense': 98, 'picea_abies': 99, 'picea_orientalis': 100, 'picea_pungens': 101, 'pinus_bungeana': 102, 'pinus_cembra': 103, 'pinus_densiflora': 104, 'pinus_echinata': 105, 'pinus_flexilis': 106, 'pinus_koraiensis': 107, 'pinus_nigra': 108, 'pinus_parviflora': 109, 'pinus_peucea': 110, 'pinus_pungens': 111, 'pinus_resinosa': 112, 'pinus_rigida': 113, 'pinus_strobus': 114, 'pinus_sylvestris': 115, 'pinus_taeda': 116, 'pinus_thunbergii': 117, 'pinus_virginiana': 118, 'pinus_wallichiana': 119, 'platanus_acerifolia': 120, 'platanus_occidentalis': 121, 'populus_deltoides': 122, 'populus_grandidentata': 123, 'populus_tremuloides': 124, 'prunus_pensylvanica': 125, 'prunus_sargentii': 126, 'prunus_serotina': 127, 'prunus_serrulata': 128, 'prunus_subhirtella': 129, 'prunus_virginiana': 130, 'prunus_yedoensis': 131, 'pseudolarix_amabilis': 132, 'ptelea_trifoliata': 133, 'pyrus_calleryana': 134, 'quercus_acutissima': 135, 'quercus_alba': 136, 'quercus_bicolor': 137, 'quercus_cerris': 138, 'quercus_coccinea': 139, 'quercus_imbricaria': 140, 'quercus_macrocarpa': 141, 'quercus_marilandica': 142, 'quercus_michauxii': 143, 'quercus_montana': 144, 'quercus_muehlenbergii': 145, 'quercus_nigra': 146, 'quercus_palustris': 147, 'quercus_phellos': 148, 'quercus_robur': 149, 'quercus_shumardii': 150, 'quercus_stellata': 151, 'quercus_velutina': 152, 'quercus_virginiana': 153, 'robinia_pseudo-acacia': 154, 'salix_babylonica': 155, 'salix_caroliniana': 156, 'salix_matsudana': 157, 'salix_nigra': 158, 'sassafras_albidum': 159, 'staphylea_trifolia': 160, 'stewartia_pseudocamellia': 161, 'styrax_japonica': 162, 'taxodium_distichum': 163, 'tilia_americana': 164, 'tilia_cordata': 165, 'tilia_europaea': 166, 'tilia_tomentosa': 167, 'tsuga_canadensis': 168, 'ulmus_americana': 169, 'ulmus_glabra': 170, 'ulmus_parvifolia': 171, 'ulmus_procera': 172, 'ulmus_pumila': 173, 'ulmus_rubra': 174, 'zelkova_serrata': 175}\n"
     ]
    }
   ],
   "source": [
    "#建立标签和索引的对应关系\n",
    "labels = df['label']\n",
    "labels = labels.unique()\n",
    "labels.sort()\n",
    "labels_idx = {label: i for i, label in enumerate(labels)}\n",
    "print(len(labels_idx))\n",
    "print(labels)\n",
    "print(labels_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:34:10.473621Z",
     "start_time": "2023-12-04T11:34:10.222598Z"
    }
   },
   "outputs": [],
   "source": [
    "#设置参数\n",
    "params = {\n",
    "    'lr': 0.001,\n",
    "    'batch_size': 64,\n",
    "    'num_epochs': 40,\n",
    "    'k_fold': 5,\n",
    "    'num_classes': 176,\n",
    "    'model_save_path': '../model/',\n",
    "    'model_name': 'seresnext50_32x4d',\n",
    "    'num_workers': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:34:11.446382Z",
     "start_time": "2023-12-04T11:34:11.394924Z"
    }
   },
   "outputs": [],
   "source": [
    "#定义数据集\n",
    "class LeavesDataset(Dataset):\n",
    "    def __init__(self, image_dirs,labels, transform=None):\n",
    "        self.image_dirs = image_dirs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_dirs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(data_dir, self.image_dirs[idx]))\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            image = torch.clamp(image, 0, 1)\n",
    "        return image, labels_idx[label]\n",
    "    \n",
    "\n",
    "#数据转换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),#缩放到224*224\n",
    "    transforms.RandomHorizontalFlip(),#随机水平翻转\n",
    "    transforms.RandomVerticalFlip(),#随机垂直翻转\n",
    "    transforms.RandomRotation(90),#随机旋转\n",
    "    #transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1,hue=0.1),#随机改变亮度、对比度、饱和度和色调\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),#标准化\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),#标准化\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:34:14.203122Z",
     "start_time": "2023-12-04T11:34:13.932805Z"
    }
   },
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:34:15.438783Z",
     "start_time": "2023-12-04T11:34:15.313089Z"
    }
   },
   "outputs": [],
   "source": [
    "class LeafClassifier(nn.Module):\n",
    "    def __init__(self, out_features=params['num_classes']):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(params['model_name'], pretrained=True)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:34:16.494987Z",
     "start_time": "2023-12-04T11:34:16.366824Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(dim=1) == y).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:34:17.363160Z",
     "start_time": "2023-12-04T11:34:17.303091Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, params):\n",
    "    '''\n",
    "    train_loader: 训练数据集\n",
    "    model: 模型\n",
    "    criterion: 损失函数\n",
    "    optimizer: 优化器\n",
    "    epoch: 当前轮数\n",
    "    params: 参数\n",
    "    '''\n",
    "    metric = Accumulator(2)#记录损失和准确率\n",
    "    model.train()\n",
    "    n = len(train_loader)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        metric.add(loss.item() , accuracy(outputs, labels))\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch+1, params['num_epochs'], metric[0]/n, metric[1]/n))\n",
    "    return metric[0]/n, metric[1]/n\n",
    "\n",
    "def validate(valid_loader, model, criterion, epoch, params):\n",
    "    '''\n",
    "    valid_loader: 验证数据集\n",
    "    model: 模型\n",
    "    criterion: 损失函数\n",
    "    epoch: 当前轮数\n",
    "    params: 参数\n",
    "    '''\n",
    "    metric = Accumulator(2)#记录损失和准确率\n",
    "    model.eval()\n",
    "    n = len(valid_loader)\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(valid_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            metric.add(loss.item() , accuracy(outputs, labels))\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch+1, params['num_epochs'], metric[0]/n, metric[1]/n))\n",
    "    return metric[0]/n, metric[1]/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:34:18.230861Z",
     "start_time": "2023-12-04T11:34:18.158383Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_loss_acc(train_loss, train_acc, valid_loss, valid_acc):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='valid_loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_acc, label='train_acc')\n",
    "    plt.plot(valid_acc, label='valid_acc')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:34:40.060496Z",
     "start_time": "2023-12-04T11:34:19.424968Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/chenyuhan/anaconda3/envs/ml_torch/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chenyuhan/anaconda3/envs/ml_torch/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'LeavesDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/chenyuhan/Documents/ML/MLproject/code/classify-leaves.ipynb 单元格 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenyuhan/Documents/ML/MLproject/code/classify-leaves.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(params[\u001b[39m'\u001b[39m\u001b[39mnum_epochs\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenyuhan/Documents/ML/MLproject/code/classify-leaves.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     metric \u001b[39m=\u001b[39m Accumulator(\u001b[39m4\u001b[39m)\u001b[39m#记录损失和准确率\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chenyuhan/Documents/ML/MLproject/code/classify-leaves.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train(train_loader, model, criterion, optimizer, epoch, params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenyuhan/Documents/ML/MLproject/code/classify-leaves.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     valid_loss, valid_acc \u001b[39m=\u001b[39m validate(valid_loader, model, criterion, epoch, params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenyuhan/Documents/ML/MLproject/code/classify-leaves.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     metric\u001b[39m.\u001b[39madd(train_loss, train_acc, valid_loss, valid_acc)\n",
      "\u001b[1;32m/Users/chenyuhan/Documents/ML/MLproject/code/classify-leaves.ipynb 单元格 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenyuhan/Documents/ML/MLproject/code/classify-leaves.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenyuhan/Documents/ML/MLproject/code/classify-leaves.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chenyuhan/Documents/ML/MLproject/code/classify-leaves.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (images, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenyuhan/Documents/ML/MLproject/code/classify-leaves.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chenyuhan/Documents/ML/MLproject/code/classify-leaves.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_iterator()\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1032\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m w\u001b[39m.\u001b[39mstart()\n\u001b[1;32m   1040\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1041\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_torch/lib/python3.11/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Popen(\u001b[39mself\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_torch/lib/python3.11/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39mget_context()\u001b[39m.\u001b[39mProcess\u001b[39m.\u001b[39m_Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_torch/lib/python3.11/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_torch/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_torch/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_launch(process_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_torch/lib/python3.11/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[39m.\u001b[39mwrite(fp\u001b[39m.\u001b[39mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#使用交叉验证法\n",
    "kf = StratifiedKFold(n_splits=params['k_fold'], shuffle=True, random_state=2023)\n",
    "\n",
    "for k, (train_index, test_index) in enumerate(kf.split(df['image'], df['label'])):\n",
    "    \n",
    "    train_img,valid_img = df['image'].iloc[train_index],df['image'].iloc[test_index]\n",
    "    train_label,valid_label = df['label'].iloc[train_index],df['label'].iloc[test_index]\n",
    "\n",
    "    train_img_dirs = [os.path.join(data_dir, path) for path in train_img]\n",
    "    valid_img_dirs = [os.path.join(data_dir, path) for path in valid_img]\n",
    "    \n",
    "    train_dataset = LeavesDataset(train_img_dirs, train_label, transform=train_transform)\n",
    "    valid_dataset = LeavesDataset(valid_img_dirs, valid_label, transform=valid_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True, num_workers=params['num_workers'])\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=params['batch_size'], shuffle=False, num_workers=params['num_workers'])\n",
    "\n",
    "    model = LeafClassifier().to(device)\n",
    "    model = nn.DataParallel(model)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "    metrics = []\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        metric = Accumulator(4)#记录损失和准确率\n",
    "        train_loss, train_acc = train(train_loader, model, criterion, optimizer, epoch, params)\n",
    "        valid_loss, valid_acc = validate(valid_loader, model, criterion, epoch, params)\n",
    "        metric.add(train_loss, train_acc, valid_loss, valid_acc)\n",
    "        metrics.append(metric.data)\n",
    "        torch.save(model.state_dict(), params['model_save_path'] + str(k)+\"fold_\"+str(epoch)+\"epoch\" + '.pth')\n",
    "    train_loss, train_acc, valid_loss, valid_acc = zip(*metrics)\n",
    "    show_loss_acc(train_loss, train_acc, valid_loss, valid_acc)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集\n",
    "def TestDataset(Dataset):\n",
    "    def __init__(self, samples_dir, transform=None):\n",
    "        self.samples = pd.read_csv(samples_dir)\n",
    "        self.image_paths = self.samples.iloc[:, 0]\n",
    "        self.transform = transform  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = plt.imread(os.path.join(data_dir, self.image_paths[idx]))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "    \n",
    "\n",
    "#测试模型\n",
    "def load_model(model_path):\n",
    "    model = LeafClassifier().to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model\n",
    "\n",
    "def predict(models, test_loader):\n",
    "    preds = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, _ in test_loader:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                preds.append(outputs)\n",
    "    preds = torch.stack(preds).mean(0).argmax(1)\n",
    "    return preds\n",
    "\n",
    "test_df = pd.read_csv(test_samples_dir)\n",
    "test_dataset = TestDataset(test_samples_dir, transform=valid_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "models = []\n",
    "for i in range(params['k_fold']):\n",
    "    model = load_model(params['model_save_path'] + 'model_{}.pth'.format(i+1))\n",
    "    models.append(model)\n",
    "\n",
    "preds = predict(models, test_loader)\n",
    "preds = [labels[i] for i in preds]\n",
    "test_df['label'] = preds\n",
    "test_df.to_csv(data_dir + 'submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
